{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:31:26.095537Z",
     "start_time": "2019-07-20T08:31:21.204Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:31:27.722859Z",
     "start_time": "2019-07-20T08:31:27.717902Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_ag_news(split='train'):\n",
    "    data = pd.read_csv('data/ag_news_csv/{}.csv'.format(split),header=-1)\n",
    "    labels = data[0].values.tolist()\n",
    "    texts = data[1]+data[2]\n",
    "    texts = texts.values.tolist()\n",
    "    return texts,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:31:29.794973Z",
     "start_time": "2019-07-20T08:31:29.103519Z"
    }
   },
   "outputs": [],
   "source": [
    "texts,labels = load_ag_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:31:32.440692Z",
     "start_time": "2019-07-20T08:31:32.426589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wall St. Bears Claw Back Into the Black (Reuters)Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:31:35.076606Z",
     "start_time": "2019-07-20T08:31:35.065634Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(texts):\n",
    "    #只保留字母和数字空格\n",
    "    texts = [re.sub(r'[^A-Za-z0-9 ]','',text) for text in texts]\n",
    "    #去空格字母小写\n",
    "    texts = [[word.strip().lower() for word in text.split(' ')] for text in texts]\n",
    "    #去停用词\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    texts = [list(filter(lambda x:x not in english_stopwords,text)) for text in texts]\n",
    "    #Stemming\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    texts = [[stemmer.stem(word) for word in text] for text in texts]\n",
    "    #Lemma\n",
    "    lemma = WordNetLemmatizer()\n",
    "    texts = [[lemma.lemmatize(word) for word in text] for text in texts]\n",
    "    texts = [' '.join(text) for text in texts]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:08.625611Z",
     "start_time": "2019-07-20T08:31:37.689863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wall st bear claw back black reutersreut  shortsel wall street dwindlingband ultracyn see green'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=text_preprocessing(texts)\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label不是从0开始的，而是1，2，3，4需要手动处理去掉第一维的onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:12.826622Z",
     "start_time": "2019-07-20T08:33:12.822604Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_label_for_model(labels):\n",
    "    onehot_labels = np_utils.to_categorical(labels)\n",
    "    onehot_labels = onehot_labels[:,1:]\n",
    "    return onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:14.544402Z",
     "start_time": "2019-07-20T08:33:14.529441Z"
    }
   },
   "outputs": [],
   "source": [
    "onehot_labels = preprocess_label_for_model(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:16.254746Z",
     "start_time": "2019-07-20T08:33:16.207622Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = train_test_split(texts,onehot_labels,test_size=0.001,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:19.579977Z",
     "start_time": "2019-07-20T08:33:19.576550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:22.873795Z",
     "start_time": "2019-07-20T08:33:22.864975Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text_for_model(x,token=None,dict_size=8000,max_length=128):\n",
    "    if token is None:\n",
    "        token = Tokenizer(num_words=dict_size)\n",
    "        token.fit_on_texts(x)\n",
    "    texts_seq = token.texts_to_sequences(x)\n",
    "    texts_seq_pad = sequence.pad_sequences(texts_seq,maxlen=max_length)\n",
    "    return texts_seq_pad,token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:35.916712Z",
     "start_time": "2019-07-20T08:33:26.181321Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_seq,token = preprocess_text_for_model(x_train)\n",
    "x_val_seq,_ = preprocess_text_for_model(x_val,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:39.237256Z",
     "start_time": "2019-07-20T08:33:39.232298Z"
    }
   },
   "outputs": [],
   "source": [
    "dimension_output=4\n",
    "dict_size=8000\n",
    "embedded_size=128\n",
    "maxlen=128\n",
    "pooling_size=5\n",
    "num_layers=2\n",
    "size_layer=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:42.571846Z",
     "start_time": "2019-07-20T08:33:42.567858Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:46.349309Z",
     "start_time": "2019-07-20T08:33:45.913036Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, maxlen])\n",
    "Y = tf.placeholder(tf.float32, [None, dimension_output])\n",
    "is_training = tf.placeholder_with_default(True,shape=(),name='is_training')\n",
    "\n",
    "with tf.name_scope('embedding'):\n",
    "    encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embedded_size], -1, 1))\n",
    "    encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, X)\n",
    "    encoder_embedded = tf.expand_dims(encoder_embedded,-1)\n",
    "    drop1=tf.layers.dropout(encoder_embedded,0.5,training=is_training)\n",
    "\n",
    "with tf.name_scope('conv'):\n",
    "    conv1 = tf.layers.conv2d(drop1,filters=16,kernel_size=3,strides=1,padding='VALID',name='conv1',activation='relu')\n",
    "    pool1 = tf.layers.max_pooling2d(conv1,pool_size=2,strides=2,padding='VALID',name='pooling1')\n",
    "    conv2 = tf.layers.conv2d(pool1,filters=32,kernel_size=4,strides=1,padding='VALID',name='conv2',activation='relu')\n",
    "    pool2 = tf.layers.max_pooling2d(conv2,pool_size=2,strides=2,padding='VALID',name='pooling2')\n",
    "\n",
    "with tf.name_scope('hidden'):\n",
    "    flatten = tf.reshape(pool2,shape=(-1,32*30*30),name='flatten')\n",
    "    hidden = tf.layers.dense(flatten,units=128,kernel_initializer=tf.variance_scaling_initializer,activation='relu',name='hidden')\n",
    "    drop2=tf.layers.dropout(hidden,0.5,training=is_training)\n",
    "with tf.name_scope('output'):\n",
    "    logits = tf.layers.dense(hidden,units=4,kernel_initializer=tf.variance_scaling_initializer,name='logits')\n",
    "    pred = tf.argmax(logits, 1)\n",
    "with tf.name_scope('train'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 1e-3).minimize(cost)\n",
    "with tf.name_scope('eval'):\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:49.718295Z",
     "start_time": "2019-07-20T08:33:49.714304Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_batch(x,y,batch_size):\n",
    "    index = np.random.permutation(len(x))\n",
    "    n_batch = len(x) // batch_size\n",
    "    for batch_index in np.array_split(index,n_batch):\n",
    "        x_batch,y_batch = x[batch_index],y[batch_index]\n",
    "        yield x_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:53.094943Z",
     "start_time": "2019-07-20T08:33:53.089954Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:33:56.470988Z",
     "start_time": "2019-07-20T08:33:56.459172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:35:34.872237Z",
     "start_time": "2019-07-20T08:35:34.337689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/cnn_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, \"model/cnn_model.ckpt\")\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for x_batch,y_batch in shuffle_batch(x_train_seq,y_train,batch_size):\n",
    "#         sess.run(optimizer,feed_dict={X:x_batch,Y:y_batch,is_training:True})\n",
    "#     l,a = sess.run([cost,accuracy],feed_dict={X:x_val_seq,Y:y_val,is_training:False})\n",
    "#     print('epoch:%d loss:%.2f acc:%.2f' %(epoch,l,a))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:35:39.023230Z",
     "start_time": "2019-07-20T08:35:38.962312Z"
    }
   },
   "outputs": [],
   "source": [
    "sents_test,labels_test=load_ag_news('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:35:48.416869Z",
     "start_time": "2019-07-20T08:35:42.723379Z"
    }
   },
   "outputs": [],
   "source": [
    "texts_test=text_preprocessing(sents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:35:52.265387Z",
     "start_time": "2019-07-20T08:35:52.258474Z"
    }
   },
   "outputs": [],
   "source": [
    "onehot_labels_test = preprocess_label_for_model(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:35:56.403510Z",
     "start_time": "2019-07-20T08:35:56.030765Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_seq,_=preprocess_text_for_model(sents_test,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:36:11.756791Z",
     "start_time": "2019-07-20T08:36:00.145280Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for item in x_test_seq:\n",
    "    p = sess.run(pred,feed_dict={X:item.reshape(-1,128),is_training:False})\n",
    "    y_pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:36:19.070296Z",
     "start_time": "2019-07-20T08:36:19.059421Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result = [item.tolist()[0]+1 for item in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:36:26.303541Z",
     "start_time": "2019-07-20T08:36:26.294593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8210526315789474"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(labels_test,final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T07:52:08.665733Z",
     "start_time": "2019-07-20T07:52:06.051335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/cnn_model.ckpt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"model/cnn_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T08:36:33.514093Z",
     "start_time": "2019-07-20T08:36:33.510106Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
